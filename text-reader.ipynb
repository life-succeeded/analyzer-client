{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc16f68",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "!pip install fastapi easyocr pyngrok uvicorn python-multipart\n",
    "from fastapi import FastAPI, UploadFile, File, HTTPException\n",
    "from fastapi.responses import JSONResponse\n",
    "import easyocr\n",
    "import io\n",
    "from PIL import Image\n",
    "import uvicorn\n",
    "from fastapi.middleware.cors import CORSMiddleware\n",
    "import nest_asyncio\n",
    "import pyngrok.ngrok\n",
    "import asyncio\n",
    "import signal\n",
    "from pydantic import BaseModel\n",
    "import base64\n",
    "from typing import List, Tuple, Dict, Any\n",
    "import numpy as np\n",
    "\n",
    "app = FastAPI(title=\"EasyOCR API\")\n",
    "app.add_middleware(\n",
    "    CORSMiddleware,\n",
    "    allow_origins=[\"*\"],\n",
    "    allow_credentials=True,\n",
    "    allow_methods=[\"*\"],\n",
    "    allow_headers=[\"*\"],\n",
    ")\n",
    "\n",
    "def convert_bbox_to_serializable(bbox) -> List[List[float]]:\n",
    "    return [[float(x) for x in point] for point in bbox]\n",
    "\n",
    "reader = easyocr.Reader(['en', 'ru'])\n",
    "\n",
    "\n",
    "@app.post(\"/ocr\")\n",
    "async def recognize_text(file: UploadFile = File(...)):\n",
    "    try:\n",
    "        if not file.content_type.startswith('image/'):\n",
    "            raise HTTPException(status_code=400, detail=\"–§–∞–π–ª –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º\")\n",
    "        contents = await file.read()\n",
    "        image = Image.open(io.BytesIO(contents))\n",
    "\n",
    "        if image.mode != 'RGB':\n",
    "            image = image.convert('RGB')\n",
    "\n",
    "        image_np = np.array(image)\n",
    "        result = reader.readtext(image_np)\n",
    "        texts = [detection[1] for detection in result]\n",
    "        full_text = \" \".join(texts)\n",
    "\n",
    "        serializable_result = []\n",
    "        for detection in result:\n",
    "            bbox = []\n",
    "            for point in detection[0]:\n",
    "                if hasattr(point, 'tolist'):\n",
    "                    bbox.append(point.tolist())\n",
    "                else:\n",
    "                    bbox.append([float(x) for x in point])\n",
    "\n",
    "            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º confidence score\n",
    "            confidence = float(detection[2])\n",
    "\n",
    "            serializable_result.append({\n",
    "                \"bbox\": bbox,\n",
    "                \"text\": detection[1],\n",
    "                \"confidence\": confidence\n",
    "            })\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"text\": full_text,\n",
    "            \"details\": serializable_result\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=f\"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {str(e)}\")\n",
    "\n",
    "\n",
    "class OcrItem(BaseModel):\n",
    "    image_base64: str\n",
    "\n",
    "@app.post(\"/ocr-base\")\n",
    "async def recognize_text(\n",
    "    item: OcrItem\n",
    "):\n",
    "    try:\n",
    "        if \",\" in item.image_base64:\n",
    "            item.image_base64 = item.image_base64.split(\",\")[1]\n",
    "\n",
    "        image_data = base64.b64decode(item.image_base64)\n",
    "        image = Image.open(io.BytesIO(image_data))\n",
    "\n",
    "        result = reader.readtext(image)\n",
    "        print('result', result)\n",
    "        processed_result = []\n",
    "        for detection in result:\n",
    "            bbox, text, confidence = detection\n",
    "            serializable_bbox = convert_bbox_to_serializable(bbox)\n",
    "            serializable_confidence = float(confidence)\n",
    "\n",
    "            processed_result.append(\n",
    "                (serializable_bbox, text, serializable_confidence)\n",
    "            )\n",
    "\n",
    "        texts = [detection[1] for detection in processed_result]\n",
    "        full_text = \" \".join(texts)\n",
    "\n",
    "        return {\n",
    "            \"status\": \"success\",\n",
    "            \"text\": full_text,\n",
    "            \"details\": processed_result,\n",
    "        }\n",
    "\n",
    "    except Exception as e:\n",
    "        raise HTTPException(\n",
    "            status_code=400,\n",
    "            detail=f\"–û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {str(e)}\"\n",
    "        )\n",
    "\n",
    "async def shutdown_signal_handler():\n",
    "    print(\"Shutting down server...\")\n",
    "\n",
    "def main():\n",
    "    NGROK_AUTH_TOKEN = \"\"  # —Ç–æ–∫–µ–Ω —Å–≤–æ–π –±–µ—Ä–∏\n",
    "    pyngrok.ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
    "    ngrok_tunnel = pyngrok.ngrok.connect(8000)\n",
    "    print('üëâ –¢–≤–æ–π URL API:', ngrok_tunnel.public_url)\n",
    "\n",
    "    config = uvicorn.Config(\n",
    "        app,\n",
    "        host=\"0.0.0.0\",\n",
    "        port=8000,\n",
    "        log_level=\"debug\"\n",
    "    )\n",
    "    server = uvicorn.Server(config)\n",
    "\n",
    "    loop = asyncio.get_event_loop()\n",
    "    for sig in (signal.SIGTERM, signal.SIGINT):\n",
    "        loop.add_signal_handler(\n",
    "            sig,\n",
    "            lambda: asyncio.create_task(shutdown_signal_handler())\n",
    "        )\n",
    "\n",
    "    nest_asyncio.apply()\n",
    "    try:\n",
    "        loop.run_until_complete(server.serve())\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"Server stopped by user\")\n",
    "    finally:\n",
    "        pyngrok.ngrok.disconnect(ngrok_tunnel.public_url)\n",
    "        print(\"ngrok tunnel closed\")\n",
    "\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
